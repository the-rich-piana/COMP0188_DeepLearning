{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGkVr76GaECI"
      },
      "source": [
        "# Variational Autoencoders\n",
        "Build a Convolutional Variational AutoEncoder and achieve best possible reconstruction and latent space disentanglement. Then answer the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByQqguASZ1hK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import altair as alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udrmU49Banm8"
      },
      "outputs": [],
      "source": [
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv4_b1RmoF7J"
      },
      "outputs": [],
      "source": [
        "def show(img):\n",
        "    npimg = img.cpu().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJ1_lMbapjM"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "\n",
        "#######################################################################\n",
        "#                       ** START OF YOUR CODE **\n",
        "#######################################################################\n",
        "\n",
        "#                 ** MODIFY CODE HERE IF NECESSARY **\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "data_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def denormalize(x):\n",
        "    return x\n",
        "\n",
        "#######################################################################\n",
        "#                       ** END OF YOUR CODE **\n",
        "#######################################################################\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=data_transforms,\n",
        ")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    training_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Download test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=data_transforms,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6MwyOY_cG6n"
      },
      "outputs": [],
      "source": [
        "sample_inputs, _ = next(iter(test_dataloader))\n",
        "fixed_input = sample_inputs[0:32, :, :, :]\n",
        "# visualize the original images of the last batch of the test set\n",
        "img = make_grid(denormalize(fixed_input), nrow=8, padding=2, normalize=False,\n",
        "                scale_each=False, pad_value=0)\n",
        "plt.figure()\n",
        "show(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFWEtLecPRv"
      },
      "source": [
        "# Variational Auto Encoders (VAEs)\n",
        "\n",
        "<figure>\n",
        "  <img src=\"https://blog.bayeslabs.co/assets/img/vae-gaussian.png\" style=\"width:60%\">\n",
        "  <figcaption>\n",
        "    Fig.1 - VAE Diagram (with a Guassian prior), taken from <a href=\"https://blog.bayeslabs.co/2019/06/04/All-you-need-to-know-about-Vae.html\">2</a>.\n",
        "  </figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3VnYv1eE9y"
      },
      "source": [
        "## Build a convolutional VAE\n",
        "The only requirement is that it contains convolutions both in the encoder and decoder. You can still use some linear layers if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVqQmpyucQOu"
      },
      "outputs": [],
      "source": [
        "# Convolutional VAE implementation here\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "    def encode(self, x):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "    def decode(self, z):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "model = VAE(latent_dim).to(device)\n",
        "summary(model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtqKZ4tYiSWf"
      },
      "source": [
        "Briefly Explain your architectural choices\n",
        "\n",
        "<font color='red'>***YOUR ANSWER***</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpwY-K8IceIx"
      },
      "source": [
        "## Defining a Loss\n",
        "\n",
        "The Beta VAE loss, with encoder $q$ and decoder $p$:\n",
        "$$ L=\\mathbb{E}_{q_\\phi(z \\mid X)}[\\log p_\\theta(X \\mid z)]-\\beta D_{K L}[q_\\phi(z \\mid X) \\| p_\\theta(z)]$$\n",
        "\n",
        "The loss you implement depends on your choice of latent prior and model outputs.\n",
        "\n",
        "There exist different solutions that are equally correct. Depending on your assumptions you might want to do a data preprocessing step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElhBWYfqdmQQ"
      },
      "outputs": [],
      "source": [
        "def loss_function_VAE(recon_x, x, mu, logvar, beta):\n",
        "        #######################################################################\n",
        "        #                       ** START OF YOUR CODE **\n",
        "        #######################################################################\n",
        "\n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        #                       ** END OF YOUR CODE **\n",
        "        #######################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX1Y3g8yg3OJ"
      },
      "source": [
        "## Train and plot\n",
        "\n",
        "Train the VAE and plot:\n",
        "\n",
        "1.   The total loss curves for train and test (on the same plot)\n",
        "2.   The reconstruction losses for train and test (on the same plot)\n",
        "3.   The KL losses for train and test (on the same plot)\n",
        "\n",
        "(x-axis: epochs, y-axis: loss)\n",
        "\n",
        "You may want to have different plots with differente values of $\\beta$.\n",
        "\n",
        "Hint: You can modify the training scripts provided in previous tutorials to record the required information, and use matplotlib to plot them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GECQ30spg2-L"
      },
      "outputs": [],
      "source": [
        "# Training code\n",
        "\n",
        "#######################################################################\n",
        "#                       ** START OF YOUR CODE **\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "#                       ** END OF YOUR CODE **\n",
        "#######################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzJw7M33hh3s"
      },
      "outputs": [],
      "source": [
        "# Plotting code\n",
        "\n",
        "#######################################################################\n",
        "#                       ** START OF YOUR CODE **\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "#                       ** END OF YOUR CODE **\n",
        "#######################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTq2lM_a1h5A"
      },
      "source": [
        "Observe:\n",
        "\n",
        "1.   Loss curves (reconstruction and KL divergence)\n",
        "2.   How different values of $\\beta$ affect your training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okv5zjxVjgJj"
      },
      "source": [
        "## Sample and reconstruction quality\n",
        "Simply run the below cell to visualize the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLKbkeu6nHXK"
      },
      "outputs": [],
      "source": [
        "# Input images\n",
        "model.eval()\n",
        "sample_inputs, _ = next(iter(test_dataloader))\n",
        "fixed_input = sample_inputs[0:32, :, :, :]\n",
        "\n",
        "# visualize the original images of the last batch of the test set\n",
        "img = make_grid(denormalize(fixed_input), nrow=8, padding=2, normalize=False,\n",
        "                scale_each=False, pad_value=0)\n",
        "plt.figure()\n",
        "show(img)\n",
        "\n",
        "# Reconstructed images\n",
        "with torch.no_grad():\n",
        "\n",
        "    _, _, recon_batch = model(sample_inputs.to(device))\n",
        "    recon_batch = recon_batch.unsqueeze(1).reshape(-1,1,28,28)\n",
        "    recon_batch = recon_batch[0:32, :, :, :]\n",
        "    recon_batch = recon_batch.cpu()\n",
        "    recon_batch = make_grid(denormalize(recon_batch), nrow=8, padding=2, normalize=False,\n",
        "                            scale_each=False, pad_value=0)\n",
        "    plt.figure()\n",
        "    show(recon_batch)\n",
        "\n",
        "# Generated Images\n",
        "n_samples = 256\n",
        "z = torch.randn(n_samples,latent_dim).to(device)\n",
        "with torch.no_grad():\n",
        "\n",
        "    samples = model.decode(z)\n",
        "    samples = samples.unsqueeze(1).reshape(-1,1,28,28)\n",
        "    samples = samples.cpu()\n",
        "    samples = make_grid(denormalize(samples), nrow=16, padding=2, normalize=False,\n",
        "                            scale_each=False, pad_value=0)\n",
        "    plt.figure(figsize = (8,8))\n",
        "    show(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRlQXC2vr8cq"
      },
      "source": [
        "## T-SNE on Embeddings\n",
        "Extract the latent representations of the test set and visualize them using [T-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)\n",
        "\n",
        "Run the below cells (no coding required).\n",
        "\n",
        "Qualitatively assess the learned representations of your model using the T-SNE plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_aIqMV07kER"
      },
      "outputs": [],
      "source": [
        "alt.data_transformers.disable_max_rows()\n",
        "\n",
        "def plot_tsne(tsne_xy, dataloader, num_points=1000):\n",
        "\n",
        "    images, labels = zip(*[(x[0].numpy()[0,:,:,None], x[1]) for x in dataloader.dataset])\n",
        "\n",
        "    num_points = min(num_points, len(labels))\n",
        "    data = pd.DataFrame({'x':tsne_xy[:, 0], 'y':tsne_xy[:, 1], 'label':labels,\n",
        "                        'image': images})\n",
        "    data = data.sample(n=num_points, replace=False)\n",
        "\n",
        "    alt.renderers.set_embed_options('light')\n",
        "    selection = alt.selection_single(on='mouseover', clear='false', nearest=True,\n",
        "                                    init={'x':data['x'][data.index[0]], 'y':data['y'][data.index[0]]})\n",
        "    scatter = alt.Chart(data).mark_circle().encode(\n",
        "        alt.X('x:N',axis=None),\n",
        "        alt.Y('y:N',axis=None),\n",
        "        color=alt.condition(selection,\n",
        "                            alt.value('lightgray'),\n",
        "                            alt.Color('label:N')),\n",
        "        size=alt.value(100),\n",
        "        tooltip='label:N'\n",
        "    ).add_selection(\n",
        "        selection\n",
        "    ).properties(\n",
        "        width=400,\n",
        "        height=400\n",
        "    )\n",
        "\n",
        "    digit  = alt.Chart(data).transform_filter(\n",
        "        selection\n",
        "    ).transform_window(\n",
        "        index='count()'           # number each of the images\n",
        "    ).transform_flatten(\n",
        "        ['image']                 # extract rows from each image\n",
        "    ).transform_window(\n",
        "        row='count()',            # number the rows...\n",
        "        groupby=['index']         # ...within each image\n",
        "    ).transform_flatten(\n",
        "        ['image']                 # extract the values from each row\n",
        "    ).transform_window(\n",
        "        column='count()',         # number the columns...\n",
        "        groupby=['index', 'row']  # ...within each row & image\n",
        "    ).mark_rect(stroke='black',strokeWidth=0).encode(\n",
        "        alt.X('column:O', axis=None),\n",
        "        alt.Y('row:O', axis=None),\n",
        "        alt.Color('image:Q',sort='descending',\n",
        "            scale=alt.Scale(scheme=alt.SchemeParams('lightgreyteal',\n",
        "                            extent=[1, 0]),\n",
        "\n",
        "            ),\n",
        "            legend=None\n",
        "        ),\n",
        "    ).properties(\n",
        "        width=400,\n",
        "        height=400,\n",
        "    )\n",
        "\n",
        "    return scatter | digit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4ZShXbssS4S"
      },
      "outputs": [],
      "source": [
        "# TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "for t, (x, y) in enumerate(test_dataloader):\n",
        "    if t == 0:\n",
        "        data = x\n",
        "        labels = y\n",
        "    else:\n",
        "        data = torch.cat((data, x))\n",
        "        labels = torch.cat((labels, y))\n",
        "\n",
        "# Then let's apply dimensionality reduction with the trained encoder\n",
        "\n",
        "with torch.no_grad():\n",
        "    data = data.to(device)\n",
        "    mu, logvar = model.encode(data)\n",
        "    z = (model.reparametrize(mu, logvar)).cpu().detach().numpy()\n",
        "\n",
        "z_embedded = TSNE(n_components=2).fit_transform(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRbmzLLm-mzL"
      },
      "outputs": [],
      "source": [
        "plot_tsne(z_embedded, test_dataloader, num_points=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-28KXeEkxga7"
      },
      "source": [
        "### Discussion\n",
        "Analyze and discuss the visualized T-SNE representations\n",
        "\n",
        "1. What role do the KL loss term and $\\beta$ have?\n",
        "2. Can you find any outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolating in $z$\n",
        "Perform a linear interpolation in the latent space of the autoencoder by choosing any two digits from the test set. What do you observe regarding the transition from one digit to the other?\n"
      ],
      "metadata": {
        "id": "GdZuQ4y3i6G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolate digits\n",
        "#######################################################################\n",
        "#                       ** START OF YOUR CODE **\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "#                       ** END OF YOUR CODE **\n",
        "#######################################################################"
      ],
      "metadata": {
        "id": "7TfSAXorijir"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}